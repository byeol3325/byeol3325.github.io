---
title:  "[Computer Vision] Depth Estimation에 대해" 
categories: research
tag: [python, studying, 3D, point cloud, computer vision, cv, depth estimation]
date: 2024-07-29
toc: true
sidebar:
    nav: "docs"
last_modified_at: 2024-07-30
---

**깊이 추정**은 컴퓨터 비전과 로봇 공학에서 중요한 과제로, **장면에서 객체까지의 거리를 파악하는 기술**입니다. 다양하게 활용되며 연구되고 있으며, **실 세계를 이해하는데 근간이 되는 기술**이기 때문에 정리할 필요가 있어 이렇게 글을 쓰게 되었습니다. (본인 공부 및 기록용)😁

# 깊이 추정(Depth Estimation)이란?
깊이 추정은 보는 **주체와 객체까지의 거리를 파악하는 기술**입니다. 이러한 정보는 **자율주행, 3D 모델링, 증강 현실 등 다양한 분야에서 이용**되고 있습니다. 

# 깊이 추정 방법
깊이 추정 방법에는 **다양한 센서들을 활용**해 다양한 방법들이 존재하며 본 글에서는 간략하게 설명하고 이후 자세히 다룰 예정입니다. 링크 또한 참조할 예정.

## 1. 전통적인 방법
사람이 객체의 거리와 3차원 정보를 얻는 것과 비슷한 원리로, 기하학적 원리와 알고리즘에 기반합니다.
### 1-1. [삼각 측량(Triangulation)](https://en.wikipedia.org/wiki/Triangulation)
- **두 지점의 알려진 위치와 각도**를 이용하여 같이 보는 지점(overview)까지의 거리를 계산합니다. 
- 주로 **여러 카메라을 이용하는 시스템**에서 사용됩니다. (stereo 포함)

![Triangulation Example]({{site.url}}/assets/images/triangulation.png)
**Figure 1: Triangulation example [출처](https://en.wiktionary.org/wiki/triangulation)**

### 1-2. [SfM(Structure from Motion)](https://en.wikipedia.org/wiki/Structure_from_motion)
- **다른 시점에서 여러 이미지를 캡처**하고, **이 이미지들 사이의 특징점의 움직임을 분석**하여 3D 구조를 재구성하는 방법입니다.
- **카메라가 움직**여야 하며, **충분한 특징점**들을 추적할 수 있어야 합니다.
![SfM Example]({{site.url}}/assets/images/SfM.JPG)
**Figure 2: SfM example [출처](https://www.mdpi.com/2313-433X/4/8/98)**

[my github SfM project](https://github.com/byeol3325/Structure-from-motion)

### 1-3. [Optical Flow](https://en.wikipedia.org/wiki/Optical_flow)
- **같은 지점의 연속된 프레임에서 픽셀 움직임**을 분석하여 깊이 정보를 추정합니다.
- 주로 **동영상이나 연속 이미지**에서 사용됩니다.
![Optical Flow Example]({{site.url}}/assets/images/optical_flow.JPG)
**Figure 3: Optical Flow example [출처](https://www.edge-ai-vision.com/2019/03/an-introduction-to-the-nvidia-optical-flow-sdk/)**

## 2. Lidar를 사용하는 방법
**Lidar(Light Detection and Ranging)**는 **레이저 빔을 사용하여 돌아올 때 정보를 통해 환경의 깊이 정보를 측정하는 기술**입니다. 이 방법은 비용이 비싸지만, 다양한 환경에서도 **간단하면서도 높은 정확도와 해상도를 제공**합니다.

- Lidar는 레이저 펄스를 방출하고, 그 빛이 물체에 반사되어 돌아오는 시간을 측정하여 거리를 계산합니다.
- 주로 자율주행차, 드론, 3D 스캐닝 등에서 사용됩니다.

![monocular with lidar point Example]({{site.url}}/assets/images/lidar_monodepth.JPG)

**Figure 4: monocular with lidar point example [출처](https://www.researchgate.net/figure/Monocular-2D-image-a-and-the-corresponding-LiDAR-3D-Point-Cloud-b-The-projection-of_fig1_360935083)**


## 3. 단안 카메라를 사용하는 방법
단안 카메라(Monocular)를 사용하는 깊이 추정은 **하나의 이미지에서 깊이 정보를 추출**하는 방법입니다. 일반적인 카메라로도 가능하지만 **실 산업에 적용하기에는 성능이 아직 부족하다**는 단점이 있습니다.

### 3-1. 기계 학습 기반 방법

- 대규모 데이터셋을 사용하여 딥러닝 모델을 훈련시킵니다.
- 훈련된 모델은 새로운 이미지에서 깊이 지도를 예측할 수 있습니다.
- 대표적인 모델로는 [Monodepth](https://github.com/mrharicot/monodepth), [DenseDepth](https://github.com/ialhashim/DenseDepth) 등이 있으며 최근에는 **transformer**를 활용한[MonoViT](https://github.com/zxcqlf/MonoViT), **diffusion**을 활용한 [DiffusionDepth](https://github.com/duanyiqun/DiffusionDepth) 등이 있습니다.


## 4. 스테레오 카메라를 사용하는 방법
두 개의 카메라를 사용하여 깊이 정보를 추정하는 방법입니다. 인간의 두 눈으로 깊이를 인식하는 방식과 유사합니다. 하지만 **시간이 지날 수록 카메라 간의 calibration 정보가 바뀔 수 있다**는 큰 단점이 존재합니다.


### 4-1. 스테레오 매칭
- 두 카메라로부터 얻은 이미지를 비교하여 각 점의 시차(Disparity)를 계산합니다.
- 시차를 이용하여 각 점까지의 깊이를 추정합니다.
- **시차가 크면 대상이 카메라에 가깝고, 시차가 작으면 대상이 멀리** 있습니다.
- **두 카메라 사이의 베이스라인(기준선) 거리**를 알면, **시차를 통해 깊이를 정확하게 계산**할 수 있습니다.
- 일반적으로 **베이스라인이 길수록 깊이 측정의 정확도가 높아**집니다.


### 4-2. 에피폴라 기하학 (epipolar geometry)
- **두 카메라의 위치와 방향을 기반**으로 에피폴라 선[Epipolar Line](https://en.wikipedia.org/wiki/Epipolar_geometry)을 사용하여 깊이 정보를 계산합니다.
- **정확한 카메라 캘리브레이션이 필요**합니다. (높은 계산 비용)


### 4-3. 스테레오 비전 알고리즘
- **블록 매칭(Block Matching) 알고리즘**: 시차를 계산하는 기본 방법 중 하나로, 각 블록을 비교하여 시차를 계산
- **준 밀집(Semi-Global Matching, SGM) 알고리즘**: 블록 매칭의 단점을 보완한 방법으로, 여러 방향에서 매칭을 고려하여 시차를 계산합니다.
- 딥러닝 기반 알고리즘: CNN을 이용한 스테레오 매칭이 활발히 연구되고 있으며, 대표적인 예로 [PSMNet](https://github.com/JiaRenChang/PSMNet), [GANet](https://github.com/feihuzhang/GANet) 등이 있습니다.

![Block Matching Example]({{site.url}}/assets/images/depth_block_matching.JPG)
**Figure 5: Block Matching example [출처](https://www.researchgate.net/figure/Monocular-2D-image-a-and-the-corresponding-LiDAR-3D-Point-Cloud-b-The-projection-of_fig1_360935083)**


## 5. 다중 카메라 시스템
- 다중 카메라 배열: 여러대의 카메라를 배열하여 더 넓은 시야와 더 높은 정확도로 깊이 정보를 얻을 수 있습니다. 최근에는 차량에서 카메라를 5 ~ 6대를 통해 360도 모든 상황에 대한 깊이 정보를 얻으려고 하고 있습니다.
- Calibration 동기화: 다중 카메라 시스템에서는 카메라들간 정확한 캘리브레이션과 시간 동기화가 필요합니다.
![depth surround Example]({{site.url}}/assets/images/depth_surround.JPG)
**Figure 6: depth surround example [출처](https://www.tri.global/research/full-surround-monodepth-multiple-cameras)**


# 응용 분야
- 3D Reconstruction: 건축, 게임, 시뮬레이션(자연재해, 영화, CG 등) 등에서 3D 모델을 생성하기 위해 깊이 추정을 사용
- 증강 현실(AR): AR시스템에서 깊이 추정을 사용하여 현실 세계와 가상 객체를 자연스럽게 결합하는 방법
- 로봇 네비게이션: 로봇이 깊이 추정을 활용하여 장애물을 회피하고 경로를 탐색 및 진행

이것저것 공부하면서 관련 내용에 대해 계속 추가할 예정입니다. 궁금한 것들이나 추가 및 수정했으면 좋겠는 거 말해주시면 좋을 거 같아요.
좋은 하루 보내시길 바래요 :)