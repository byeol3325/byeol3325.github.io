---
title:  "[논문 리뷰] DUSt3R: Geometric 3D Vision Made Easy" 
categories: research
tag: [python, studying, 3D, point cloud, computer vision, cv, paper]
date: 2024-08-01
toc: true
toc_sticky: true
toc_label: 목차
use_math: true
sidebar:
    nav: "docs"
last_modified_at: 2024-08-01
---


다양한 3D 프로젝트들을 하면서 3D에 관심이 많아진 참에 뉴스에서 해당 기술을 보게됐다. 네이버가 발표한 기술인 DUST3R에 대해 리뷰해보려 한다. (본인 공부 및 기록용)😁

github 링크 : [DUSt3R github](https://github.com/naver/dust3r)
논문 링크 : [DUSt3R paper](https://arxiv.org/abs/2312.14132)

# 논문 요약
DUSt3R는 다양한 시점에서 촬영된 이미지로부터 3D 재구성을 수행하는 새로운 방법을 제안한다. 일반적으로 다양한 시점에서 촬영된 이미지에서 3D 재구성을 하기 위해서는 카메라 내부/외부 파라미터가 필요하다.([SfM](https://en.wikipedia.org/wiki/Structure_from_motion), [MVS](https://slazebni.cs.illinois.edu/fall22/lec20_multiview_stereo.pdf) 참고) DUSt3R은 카메라의 내부/외부 파라미터에 대한 사전 정보 없이도 3D 재구성을 가능하게 하며, 단일 이미지에서도 3D 재구성을 수행할 수 있다. 본 논문은 DUSt3R의 네트워크 구조와 학습 방법을 설명하고, 다양한 데이터셋에서의 성능을 통해 그 효용성을 입증한다.

<div class="notice--info">
    <h4> 주요 Contribution </h4>
    <pre>
-'사전 정보 없이' 다중 뷰 재구성을 수행할 수 있는 새로운 접근 방식 제안
-'포인트맵 개념을 도입'하여 기하학적 제약을 없애고, 다양한 기하학적 정보를 학습할 수 있음
-Transformer Encoder-Decoder 기반으로 하며, 이미지 쌍에서 3D 포인트 맵을 예측
-다양한 데이터 셋에서 우수한 성능을 보이고, 특히 단일 이미지와 다중 이미지 재구성 모두에서 높은 정확도를 보임
    </pre>
</div>


# 주요 내용

## 문제 정의 및 접근 방식
전통적인 방법은(SfM, MVS 등) 카메라 파라미터를 먼저 추정해야 하며(Camera Calibration), 이는 복잡하고 시간이 많이 소요되는 작업이며, 오차가 발생할 가능성도 높습니다. 또한 고도로 기하학적 지식을 필요로 하며, 많은 계산을 요구한다.

DUSt3R은 이러한 사전 정보를 필요하지 않아서 복잡한 연산을 없앴으며, 단순히 이미지 쌍들을(단일 이미지도 가능) 입력으로 받아 3D 재구성을 한다.

## 네트워크 구조
DUSt3R의 핵심은 Transformer Encoder-Decoder 구조를 사용하는 신경망이다.






이것저것 공부하면서 관련 내용에 대해 계속 추가할 예정입니다. 궁금한 것들이나 추가 및 수정했으면 좋겠는 거 말해주시면 좋을 거 같아요.
좋은 하루 보내시길 바래요 :)
