---
title:  "[Computer Vision] latent vectorì— ëŒ€í•˜ì—¬" 
categories: studying
tag: [python, studying, Computer Vision, CV, ai, ì‚¬ì§„ ì¶”ê°€ ì˜ˆì •]
date: 2024-08-15
author_profile: true
toc: true
toc_sticky: true
toc_label: ëª©ì°¨
use_math: true
sidebar:
    nav: "counts"
last_modified_at: 2024-08-15
---


ì´ ê¸€ì—ì„œëŠ” latent vectorì´ ë¬´ì—‡ì¸ì§€ ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•˜ê³ , Computer Visionì—ì„œ ì–¸ì œ ì–´ë–»ê²Œ ì“°ì´ëŠ”ì§€ ì˜ˆì‹œì™€ í•¨ê»˜ ë‹¤ë£° ì˜ˆì •ì…ë‹ˆë‹¤. (ë³¸ì¸ ê³µë¶€ ë° ê¸°ë¡ìš©)ğŸ˜


# Latent Vectorë€?

**Latent Vector(ì ì¬ ë²¡í„°)**ëŠ” ê¸°ê³„ í•™ìŠµê³¼ ë”¥ëŸ¬ë‹ì—ì„œ **ë°ì´í„°ë¥¼ ì••ì¶•**í•˜ê³  **ë‚´ì¬ëœ(ìˆ¨ê²¨ì§„) ì •ë³´ë‚˜ íŒ¨í„´ì„ ë‚˜íƒ€ë‚´ëŠ” ê³ ì°¨ì› ë²¡í„°**ì…ë‹ˆë‹¤. ì´ ë²¡í„°ëŠ” **ì›ë³¸ ë°ì´í„°ì˜ íŠ¹ì„±ì„ ì••ì¶•í•˜ì—¬ ì €ì°¨ì› ê³µê°„ì— í‘œí˜„**í•œ ê²ƒì´ë©°, ë°ì´í„° ê°„ì˜ ê´€ê³„ë‚˜ ìœ ì‚¬ì„±ì„ ë” ì˜ ì´í•´í•˜ê³  ë¶„ì„í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.


# Latent Vectorì˜ ì—­í• 

- **ë°ì´í„° ì••ì¶•** : Latent VectorëŠ” **ê³ ì°¨ì› ë°ì´í„°ë¥¼ ì‘ì€ ì°¨ì›ìœ¼ë¡œ ì••ì¶•**í•˜ë©´ì„œë„, ì›ë³¸ ë°ì´í„°ì˜ **ì¤‘ìš”í•œ íŠ¹ì„±ì„ ë³´ì¡´**í•©ë‹ˆë‹¤.


- **ì˜ë¯¸ë¥¼ í¬í•¨í•˜ëŠ” êµ¬ì¡°** : **ë°ì´í„° ê°„ì˜ ê´€ê³„ë‚˜ ìœ ì‚¬ì„±**ì„ **ë²¡í„° ê³µê°„ì—ì„œ ìˆ˜ì¹˜ì ìœ¼ë¡œ ë‚˜íƒ€ë‚´ëŠ” ë°©ì‹**ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ ë²¡í„°ë“¤ ê°„ì˜ **ê±°ë¦¬ê°€ ê°€ê¹Œìš¸ìˆ˜ë¡**, í•´ë‹¹ ë°ì´í„°ë“¤ì´ **ìœ ì‚¬í•œ íŠ¹ì„±ì„ ê³µìœ í•œë‹¤**ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.


# Latent Vectorê³¼ Embedding

ë‘˜ ë‹¤ ê³ ì°¨ì› ë°ì´í„°ë¥¼ ì €ì°¨ì›ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë°©ì‹ì„ ë‹¤ë£¨ê¸° ë•Œë¬¸ì—, ì²˜ìŒì— ê³µë¶€í•  ë•Œ ë°ì´í„°ë¥¼ Embeddingì„ í•˜ë©´ Latent Vectorê°€ ë˜ëŠ”ê±´ê°€? ë¼ ìƒê°í–ˆìŠµë‹ˆë‹¤.
ì—¬ê¸°ì„œ Latent Vectorê³¼ Embeddingì˜ ì°¨ì´ì ì„ 
ê°„ë‹¨í•˜ê³  ì‰½ê²Œ ì •ë¦¬í•˜ê³  í•©ë‹ˆë‹¤.

- Latent VectorëŠ” **ë°ì´í„°ì˜ ë‚´ì¬ëœ ì •ë³´ë¥¼ í‘œí˜„í•˜ëŠ” ì €ì°¨ì› ë²¡í„°**ë¥¼ ë§í•©ë‹ˆë‹¤. 

- Embeddingì€ ì£¼ë¡œ **í…ìŠ¤íŠ¸ë‚˜ ì¹´í…Œê³ ë¦¬í˜• ë°ì´í„°ë¥¼ ë²¡í„°ë¡œ ë³€í™˜**í•  ë•Œ ì‚¬ìš©í•˜ëŠ” ìš©ì–´ì…ë‹ˆë‹¤.

```python
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.models import Model

# ì…ë ¥ ë°ì´í„°: 28x28 í¬ê¸°ì˜ ì´ë¯¸ì§€ (MNISTì™€ ê°™ì€ ë°ì´í„°)
input_img = Input(shape=(784,))

# ì¸ì½”ë”: ì…ë ¥ ì´ë¯¸ì§€ë¥¼ 32ì°¨ì› Latent Vectorë¡œ ì••ì¶•
encoded = Dense(32, activation='relu')(input_img)

# ë””ì½”ë”: ë‹¤ì‹œ ì›ë³¸ í¬ê¸°(784ì°¨ì›)ë¡œ ë³µì›
decoded = Dense(784, activation='sigmoid')(encoded)

# ì˜¤í† ì¸ì½”ë” ëª¨ë¸
autoencoder = Model(input_img, decoded)

# ì¸ì½”ë” ëª¨ë¸ (Latent Vectorë§Œ ì¶”ì¶œ)
encoder = Model(input_img, encoded)

# ì»´íŒŒì¼ ë° í•™ìŠµ
autoencoder.compile(optimizer='adam', loss='binary_crossentropy')

# Latent Vector ìƒì„±
x_train = np.random.rand(1000, 784)  # ì˜ˆì‹œ: 1000ê°œì˜ ì´ë¯¸ì§€ ë°ì´í„° (784ì°¨ì›)
autoencoder.fit(x_train, x_train, epochs=10, batch_size=256, shuffle=True)

# ë°ì´í„°ì—ì„œ Latent Vector ì¶”ì¶œ
latent_vectors = encoder.predict(x_train)
print("Latent Vectors Shape:", latent_vectors.shape)  # (1000, 32)
```

ìœ„ ì½”ë“œëŠ” ì˜¤í† ì¸ì½”ë”ë¼ëŠ” ì‹ ê²½ë§ì„ ì´ìš©í•´ì„œ 784 ì°¨ì› ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ 32ì°¨ì› Latent Vectorë¡œ ì••ì¶•í•˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤.



```python
from tensorflow.keras.layers import Embedding
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

# ì˜ˆì‹œ ë¬¸ì¥ë“¤
sentences = ["I love machine learning", "I enjoy learning new things"]

# ë‹¨ì–´ ì¸ë±ìŠ¤ ìƒì„±
tokenizer = Tokenizer(num_words=1000)
tokenizer.fit_on_texts(sentences)
sequences = tokenizer.texts_to_sequences(sentences)
word_index = tokenizer.word_index

# ë¬¸ì¥ íŒ¨ë”© (ê¸¸ì´ë¥¼ ë§ì¶°ì¤Œ)
padded_sequences = pad_sequences(sequences, maxlen=5)

# Embedding ë ˆì´ì–´: 1000ê°œì˜ ë‹¨ì–´ë¥¼ 32ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜
embedding_layer = Embedding(input_dim=1000, output_dim=32, input_length=5)

# ì„ë² ë”©ëœ ê²°ê³¼
embedded_sequences = embedding_layer(padded_sequences)

print("Original Sequences:", sequences)
print("Padded Sequences:", padded_sequences)
print("Embedded Sequences Shape:", embedded_sequences.shape)  # (2, 5, 32)
```

ìœ„ ì½”ë“œëŠ” ë‹¨ì–´ë“¤ì„ 32ì°¨ì› Embedding ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤. ê° ë¬¸ì¥ì˜ ë‹¨ì–´ë“¤ì´ 32ì°¨ì›ì˜ ë²¡í„°ë¡œ í‘œí˜„ë˜ë©°, ì´ë¥¼ í†µí•´ ë‹¨ì–´ ê°„ì˜ ìœ ì‚¬ì„±ì„ ë²¡í„° ê³µê°„ì—ì„œ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


Embeddingì€ Latent Vectorì˜ ì¼ì¢…ì¼ ìˆ˜ ìˆì§€ë§Œ, Latent Vectorì´ ì¡°ê¸ˆ ë” í¬ê´„ì ì¸ ê°œë…ì…ë‹ˆë‹¤. í•œë²ˆ ë” ì„¤ëª…í•˜ìë©´, Embeddingì€ ì£¼ë¡œ í…ìŠ¤íŠ¸ ë°ì´í„°ì— ì‚¬ìš©ë˜ë©°, íŠ¹ì • ë°ì´í„°ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ë°©ë²•ì´ê³ , Latent Vectorì€ ë°ì´í„°ì˜ ë‚´ì œëœ ì •ë³´ë¥¼ í‘œí˜„í•˜ëŠ” ì••ì¶•ëœ ë²¡í„°ë¡œ í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜ìƒ ë“± ëª¨ë“  ì¢…ë¥˜ì˜ ë°ì´í„°ì— ì ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


ì´ê²ƒì €ê²ƒ ê³µë¶€í•˜ë©´ì„œ latent vectorì— ëŒ€í•´ ìƒˆë¡œ ì•Œê²Œ ë˜ëŠ” ë‚´ìš©ì€ ê³„ì† ì¶”ê°€í•  ì˜ˆì •ì…ë‹ˆë‹¤. ê¶ê¸ˆí•œ ê²ƒë“¤ì´ë‚˜ ì¶”ê°€ ë° ìˆ˜ì •í–ˆìœ¼ë©´ ì¢‹ê² ëŠ” ê±° ë§í•´ì£¼ì‹œë©´ ì¢‹ì„ ê±° ê°™ì•„ìš”.
ì¢‹ì€ í•˜ë£¨ ë³´ë‚´ì‹œê¸¸ ë°”ë˜ìš” :)